# Sign-Language-Detection-Project
The sign language detection is a project that involves the use of a camera and allows itself to recognize what hand gestures and sign language symbols are being displayed. 

Throughout the project, the tools used to create this were Python, Scikit Learn, Cv2, and Mediapipe. 

The way to train the model was using 26 folders containing 100 photos of each individual sign language letter. The model was able to classify the images 100%.

Despite this, the accuracy of the project is not the best, as there are some errors involving the testing of the project, including unclear images, crashing applications, and training the data. 

Despite these problems and inaccuracies, the project is now able to run and classify most sign language symbols brought up to it by the camera. 

What I have learnt from this project is understanding how to create data sets from the images for the model using Mediapipe, how to partition that data into training and testing material using libraries such as Scikit Learn, and utilize the camera library. 
